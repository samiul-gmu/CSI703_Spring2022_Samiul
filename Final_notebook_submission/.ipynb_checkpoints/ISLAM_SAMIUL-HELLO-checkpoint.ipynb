{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae9c2958",
   "metadata": {},
   "source": [
    "## Course: CSI-703 Scientific and Statistical Visualization<br>Instructor: Holly Russo, PhD\n",
    "\n",
    "### Author: Samiul Islam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4190117",
   "metadata": {},
   "source": [
    "#### It contains all the assignments that we did throughout the semester. For some of the assignments, I am using a significantly reduced dataset to fit everything in an email. I am also clearing all the outputs before I ZIP it to send (again, minimize file size). A more comprehensive notebook along with larger datasets (or a way to get those) are available on my git hub repo: https://github.com/samiul-gmu/CSI703_Spring2022_Samiul\n",
    "\n",
    "#### At the end of this notebook, I am attaching codes for a web app that I build to visualize correlations, comparisons and trends, distributions and part-to-whole, geospatial data and concepts, and qualitative data with some interactivity using streamlit. That notebook block is not meant to be run here; I have also included a .py file containing the same code that can be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74b3129",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install geopandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e94f28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50a63007",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install folium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6418c00d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4846504b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ccf076b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "from IPython.display import Image\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import geopandas as gpd\n",
    "import pickle\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from wordcloud import WordCloud\n",
    "import folium\n",
    "from folium.plugins import StripePattern\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "febadc82",
   "metadata": {},
   "source": [
    "### Assignment 1: Visualization Experience Questionnaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d52a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"Assignment_Files/Assignment1/Assignment 1_ISLAM_SAMIUL_SKILLS.pdf\", width=900, height=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb79bf3",
   "metadata": {},
   "source": [
    "### Assignment 2: Python or R: \"Hello !\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81666250",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = \"Samiul Islam\"\n",
    "g = \"G01201813\"\n",
    "msg = \"My name is \"+n+\" and my G number is \"+g\n",
    "print(msg)\n",
    "\n",
    "# web app using streamlit\n",
    "import streamlit as st\n",
    "name = st.text_input('Name', '')\n",
    "g_num = st.text_input('G-Number', '')\n",
    "st.write('Hello', name, '-', g_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d992dce",
   "metadata": {},
   "source": [
    "### Assignment 3: What does that even mean?\n",
    "\n",
    "This is a snapshot (included in the next cell) of a visualization framework that I did as a part of another project. The actual framework is built as a web app with the help of Java & JavaScript, and the different figures attached here are actually different stages of the same web app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36156a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "Image(\"Assignment_Files/Assignment3/Assignment 3_Snapshot of Covid 19 Data Visualization Framework.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e615227",
   "metadata": {},
   "source": [
    "### Assignment 4: I just can't see it.\n",
    "\n",
    "I submitted the same figure/snapshot (see the previous cell) from the assignment 3 here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "213a17b0",
   "metadata": {},
   "source": [
    "### Assignment 5: Tell me your secrets.\n",
    "\n",
    "All the questions and related answers of this assignment has been discussed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb831f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take input from the excel file and load it to a dataframe\n",
    "df = pd.read_excel('Assignment_Files/Data/forestfires.xlsx')\n",
    "# Print out head to see how the data looks like\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "532a3b75",
   "metadata": {},
   "source": [
    "Question 5.1: Is there any particular season (or months) where a forest fire is more devastating?\n",
    "\n",
    "N.B.: Can this even be answered from the given dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ee7682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate the data on monthly basis\n",
    "df_sum = df.groupby(['month']).sum()\n",
    "# subset the dataframe by keeping only the 'burnt area'\n",
    "# month is not an attribute here but index\n",
    "df_area = df_sum[['area']]\n",
    "\n",
    "# Print out to see how it looks like; found that the grouped data is not ordered by months (Jan to Dec)\n",
    "print('\\nIncorrectly ordered:')\n",
    "print(df_area)\n",
    "# Re-indexing the dataframe to fix the order of the months\n",
    "df_area = df_area.reindex(index = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct',\n",
    "       'nov', 'dec'])\n",
    "# Printing out to see if the order has been fixed\n",
    "print('\\nCorrectly ordered:')\n",
    "print(df_area)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d95be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the aggregated area for each month to identify how devasting each month was?\n",
    "# Set the size of the plot for a high-resolution plot and setup the fonts for ticks, legend, and title.\n",
    "df_area.plot.bar(figsize=(15, 10))\n",
    "plt.xticks(fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.legend(fontsize=20)\n",
    "plt.xlabel('Month',fontsize=20)\n",
    "plt.ylabel('Burnt Area (HA)',fontsize=20)\n",
    "plt.title('Burnt Forest Area by Month',fontsize=35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc41cdf",
   "metadata": {},
   "source": [
    "Answer 5.1: By looking at the above plots, one can tell that the situation worsens during August and September, and it seems to start in July and finally ends in October.\n",
    "However, having only this data and the plot above may be confusing. We are summing up all records to calculate the burnt area of each month without thinking of how balanced the data is. For example, it could be the case that we have more samples for August and September than any other months, and thus when we sum up the monthly records, their value becomes very high compared to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe3183f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate how many samples we have for each month\n",
    "dataFreqByMonth = (df.groupby('month').size())\n",
    "# Re-index to fix the order of the months\n",
    "dataFreqByMonth=dataFreqByMonth.reindex(index = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct',\n",
    "       'nov', 'dec'])\n",
    "# Print out to see how balanced the data is\n",
    "dataFreqByMonth"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f813698e",
   "metadata": {},
   "source": [
    "Answer 5.1 Cont.: We can tell from the above statistics that the data acquisition is not well distributed among months. I would not conclude without having more info regarding how the acquisition is happening. If the acquisition is triggered by some set of input parameters that successfully detects the chances of fire, then this imbalanced data is representative. If this is not the case, then further processing is needed (i.e., we can plot the area per record by month)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04430f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc = {'figure.figsize':(15,8)})\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "ax = sns.violinplot(x=\"month\", y=\"area\", data=df, gridsize=500, width=1.2, order=['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct',\n",
    "       'nov', 'dec'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7ad892",
   "metadata": {},
   "source": [
    "Answer 5.1 Cont.: The violin plot above is fancier and requires less effort but contains more information than the barplot above. It automatically groups the data by months with simple commands and shows how the data points are distributed each month."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56359cf2",
   "metadata": {},
   "source": [
    "Question 5.2: Let's assume 'area' is our target.\n",
    "How correlated are each weather/dryness-related indices to the 'area'? Also, how correlated are they to each other?\n",
    "\n",
    "List of the weather/dryness related features:\n",
    "- The Fine Fuel Moisture Code (FFMC) represents the fuel moisture of forest litter fuels under the shade of a forest canopy\n",
    "- The Duff Moisture Code (DMC) represents fuel moisture of decomposed organic material underneath the litter\n",
    "- The Drought Code (DC), much like the Keetch-Byrum Drought Index, represents drying deep into the soil\n",
    "- The Initial Spread Index (ISI) is a numeric rating of the expected rate of fire spread\n",
    "- Temperature\n",
    "- RH: Relative Humidity\n",
    "- Wind\n",
    "- Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea664ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a correlation matrix\n",
    "df_corr = df[['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain', 'area']]\n",
    "\n",
    "corr = df_corr.corr()\n",
    "mask = np.zeros_like(corr, dtype=bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "corr[mask] = np.nan\n",
    "(corr\n",
    " .style\n",
    " .background_gradient(cmap='PuOr_r', axis=None, vmin=-1, vmax=1)\n",
    " .highlight_null(null_color='#f1f1f1')\n",
    " .set_precision(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d924ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate pair plot\n",
    "\n",
    "sns.set_context( rc={\"font_scale\":30})\n",
    "\n",
    "g = sns.pairplot(df_corr, \n",
    "    kind='reg',\n",
    "    diag_kind=\"hist\",\n",
    "    corner=True,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b78d676",
   "metadata": {},
   "source": [
    "Answer 5.2: There is almost no correlation between the area and any other variable. We can tell by looking at the correlation matrix and the pair plot. I included a trendline in the pair plot, and if we focus on the 'area' row, we see completely flatlines for each pair.\n",
    "\n",
    "There are some correlation between different variables such as DMC & DC, FFMC & ISI, RH & Temp (negative corr.) etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ac7f27",
   "metadata": {},
   "source": [
    "Question 5.3: Do they (the weather/dryness variables) show any relation between them if we group them by month?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d351a009",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the month column from string to int\n",
    "df[\"month\"].replace({\"jan\": 1, \"feb\": 2, \"mar\": 3, \"apr\": 4, \"may\": 5, \"jun\": 6, \"jul\": 7, \"aug\": 8, \"sep\": 9, \"oct\": 10, \"nov\": 11, \"dec\": 12}, inplace=True)\n",
    "df[\"month\"] = df[\"month\"].astype(int)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2682d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a pair plot color-coded by months to see if they show any relation\n",
    "fig = px.parallel_coordinates(df, color=\"month\",\n",
    "                             color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "                             color_continuous_midpoint=6)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9e1c48",
   "metadata": {},
   "source": [
    "Answer 5.3: Although I couldn't find a way to assign distinct colors to each of the months, we can tell that the variables show some relations when we group them via months. For example, the teal-colored lines are basically the first quadrant, and they show high value for FFMC but low for DMC and DC. On the other hand, the last quadrant of the year shows a high value for DC while showing similar characteristics for the other two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c24f1",
   "metadata": {},
   "source": [
    "### Assignment 6: Data munging is fun!\n",
    "\n",
    "All the questions and related answers of this assignment has been discussed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e05e841d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the shape of the dataframe to see how many rows and columns we have\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a0f43d",
   "metadata": {},
   "source": [
    "Answer 6.1: Here, we have 13 columns/variables and a total of 517 rows/observations in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421eba12",
   "metadata": {},
   "source": [
    "Question 6.2: What are the different data types in the dataset (e.g., string, Boolean, integer, floating, date/time, categorical, etc.)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8106a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print out the list of variables and associated data types\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e17e730",
   "metadata": {},
   "source": [
    "Answer 6.2: We have three different data types here in this dataframe: Integer (int64), Float (float64), and Object. X, Y, and RH variables are integer variables, month and day are object types, and the rest of the variables are float types."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30e622f",
   "metadata": {},
   "source": [
    "Question 6.3: What variables would you rename to make your visualization look better?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6c3b10",
   "metadata": {},
   "source": [
    "Answer 6.3: For this particular dataset, I would keep the name of the variables as it is since they are abbreviated well. For example, the 'DC' variable represents DC (Drought Code) index from the FWI (Fire Weather Index) system. All other variables also represent a shorter and concise version of their definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c93ff62",
   "metadata": {},
   "source": [
    "Question 6.4: Describe any missing values. Using the rule of thumb in Data Visualization Made Simple, would you remove those rows or columns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bbc2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any missing values in the dataset\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd575a72",
   "metadata": {},
   "source": [
    "Answer 6.4: If we follow the above code snippet, we can see that we do not have any missing values in the dataset; hence, we do not have to remove observations or variables here. However, if we had seen some missing values in the data, it would need to be adjusted accordingly. For example, let's assume for almost all of these records, we found that the value of RH is missing. In that case, we would have removed this variable instead of eliminating the observations. On the other hand, if we had seen temp has null for three observations in the dataset, we could have removed only those three observations. There are different techniques for estimating a missing value so that we do not need to remove those observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3872a3",
   "metadata": {},
   "source": [
    "Question 6.5: What other cleaning / prep steps would you do, based on the advice in Data Visualization Made Simple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec39d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, let's see we want to work on a subset of this forest fire dataset where we only consider the observations with some burnt area.\n",
    "# Meaning, we want to only consider the observations where the 'area' value is greater than 0.0\n",
    "# By seeing the .head() functions output above, it seems evident that the value of rain is mostly zero.\n",
    "# But, we cannot tell that with certainty by only looking at the first five observations.\n",
    "# So, let's see how many observations have rain (a positive value) out of these 517 rows.\n",
    "print('Observations with rain:',len(df[df[\"rain\"] > 0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7085ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing a new dataframe by keeping observations with burnt area only\n",
    "df_burnt = df[df[\"area\"] > 0]\n",
    "\n",
    "print('Observations with rain after dropping no-burnt area(s):',len(df_burnt[df_burnt[\"rain\"] > 0]))\n",
    "\n",
    "# Since, there are only 8 records with positive values for rain, for the further analysis, I am dropping rain while selecting observations with burnt areas only\n",
    "#df_burnt = df[df[\"area\"] > 0][['X','Y','month','day','FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'area']]\n",
    "print('\\n',df_burnt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a472a027",
   "metadata": {},
   "source": [
    "Answer 6.5: Here, I am assuming that my further analysis will only require observations of burnt area. So, I have excluded those observations that do not have positive values in the burnt area variable and got 270 observations out of those 517. Also, I have seen only eight records with rain in the whole dataset, and after filtering for the burnt areas, there remain only 2. So, I have then decided to drop the 'rain' column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e6dc6a",
   "metadata": {},
   "source": [
    "### Assignment 7: Write your own evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770ef0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "IFrame(\"Assignment_Files/Assignment7/Assignment 7_Islam Samiul Evaluation Criteria for Reviewing Graphics.pdf\", width=900, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb1e8d7c",
   "metadata": {},
   "source": [
    "### Assignment 8: Visualizing correlation, comparisons, and trends.\n",
    "\n",
    "All the questions and related answers of this assignment has been discussed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb84e2da",
   "metadata": {},
   "source": [
    "Question 8.1: Do the weather/dryness variables show any relation between them if we group them by month? Below is the list of those variables.\n",
    "\n",
    "List of the weather/dryness related features:\n",
    "- The Fine Fuel Moisture Code (FFMC) represents the fuel moisture of forest litter fuels under the shade of a forest canopy\n",
    "- The Duff Moisture Code (DMC) represents fuel moisture of decomposed organic material underneath the litter\n",
    "- The Drought Code (DC), much like the Keetch-Byrum Drought Index, represents drying deep into the soil\n",
    "- The Initial Spread Index (ISI) is a numeric rating of the expected rate of fire spread\n",
    "- Temperature\n",
    "- RH: Relative Humidity\n",
    "- Wind\n",
    "- Rain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d33d77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot a pair plot color-coded by months to see if they show any relation\n",
    "fig = px.parallel_coordinates(df, color=\"month\",\n",
    "                             color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "                             color_continuous_midpoint=6,\n",
    "                              title=\"Relations between weather/dryness variables while grouping them by month\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d970eb5",
   "metadata": {},
   "source": [
    "Answer 8.1: Although I couldn't find a way to assign distinct colors to each of the months, we can tell that the variables show some relations when we group them via months. For example, the teal-colored lines are basically the first quadrant and they show high value for FFMC but low for DMC and DC. On the other hand, the last quadrant of the year shows a high value for DC while showing similar characteristics for the other two variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3525f116",
   "metadata": {},
   "source": [
    "### Assignment 9: Visualizing distributions and part-to-whole\n",
    "\n",
    "All the questions and related answers of this assignment has been discussed below:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adcb5c77",
   "metadata": {},
   "source": [
    "Question 9.1: How is the area of forest fire distributed over months?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe38032",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pie_plot = df_sum[['wind', 'area']]\n",
    "months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "df_pie_plot = df_pie_plot.loc[months]\n",
    "x = df_pie_plot.index.tolist()\n",
    "y = df_pie_plot['area'].tolist()\n",
    "percent = [100*ey / sum(y) for ey in y]\n",
    "colors = ['lightcoral','lightskyblue','yellow','yellowgreen','grey','pink','blue','darkgreen','cyan','magenta','violet','gold']\n",
    "patches, texts = plt.pie(y, colors = colors, counterclock=False, startangle=-270, radius=1.5)\n",
    "labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(x, percent)]\n",
    "plt.title('Part-to-whole\\nDistribution of\\nForest Fire\\n\\n', loc='center',fontsize=35)\n",
    "\n",
    "plt.legend(patches, labels, title = 'Month', loc='center', bbox_to_anchor=(-0.1, 1.),\n",
    "           fontsize=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef4f9af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the aggregated area for each month to identify how devasting each month was?\n",
    "# Set the size of the plot for a high-resolution plot and setup the fonts for ticks, legend, and title.\n",
    "df_bar_plot = df_area.loc[months]\n",
    "x = df_bar_plot.index.tolist()\n",
    "y = df_bar_plot['area'].tolist()\n",
    "x_pos = np.arange(len(x))\n",
    "print(x_pos)\n",
    "plt.figure(figsize=(10, 10), dpi=500)\n",
    "\n",
    "plt.bar(x_pos, y, color=['lightcoral','lightskyblue','yellow','yellowgreen','grey','pink','blue','darkgreen','cyan','magenta','violet','gold'])\n",
    "plt.xticks(x_pos, x)\n",
    "plt.xticks(fontsize=18)\n",
    "plt.yticks(fontsize=18)\n",
    "#plt.legend(fontsize=18)\n",
    "plt.xlabel('\\nMonth',fontsize=18)\n",
    "plt.ylabel('Burnt Area (HA)\\n',fontsize=18)\n",
    "plt.title('Burnt Forest Area by Month\\n',fontsize=35)\n",
    "plt.legend('',frameon=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbfc762b",
   "metadata": {},
   "source": [
    "Answer 9.1: The bar and pie plots above represent the affected areas' distribution over months and convey different key information related to the distribution. The bar plot tells us the actual burnt area by months (including unit), while the pie chart on the right tells us the corresponding percentage by showing the same visually. On top, the color palette has been kept analogous to make it easily comparable to the readers.\n",
    "\n",
    "I could have avoided these two charts and instead made one (any one of these two) with all the information from both charts (actual burnt area, percentage, and color palette to identify the corresponding months). However, I thought that route could outflow the readers and undermine the actual goal of information portrayal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe6ab6d9",
   "metadata": {},
   "source": [
    "### Assignment 10: Visualizing geospatial data\n",
    "\n",
    "All the questions and related answers of this assignment has been discussed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b58e277b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import relevant data\n",
    "data=pd.read_csv(\"Assignment_Files/Data/zipcode_wise_tweet_count_IN.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc216e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the selected subset of the US map (shapefile) containin IN only.\n",
    "# I am using a backup of the partial shapefile.\n",
    "# If you want to learn more on how I selected the subset and did a backup, you may\n",
    "# want to go over this file: 'Assignments/Assignment5_6_8_9_10_11_12/ISLAM_SAMIUL.ipynb' on\n",
    "# my git hub repo.\n",
    "with open('Assignment_Files/Data/us_map.pickle', 'rb') as handle:\n",
    "    us_map = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8f3e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the shapefile and data (head of them) to see how they look like\n",
    "print(us_map.head())\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85982cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge them based on ZCTA5CE10 which is zip-code\n",
    "map_data = us_map.merge(data, on=\"ZCTA5CE10\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31ece630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out newly created map_data to see how it looks like\n",
    "map_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61db6e18",
   "metadata": {},
   "source": [
    "Question 10.1: Given that we have access to a dataset that contains the number of tweets grouped by zip codes made from Indiana during 2014, we would like to know how they are geographically distributed. What are the key takeaways from the distribution?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbf6db99",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1, figsize=(100, 100))\n",
    "fig.patch.set_facecolor('white')\n",
    "plt.xticks(rotation=90)\n",
    "plt.yticks(fontsize=50)\n",
    "map_data.plot(column=\"t_count\", cmap=\"Reds\", linewidth=1, ax=ax, edgecolor=\"0\")\n",
    "plt.title('\\n\\nDistribution of Tweets Made from Indiana during 2014\\nMap is Sub-divided into Zip Codes', fontdict = {'fontsize' : 150})\n",
    "bar_info = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=0, vmax= max(map_data['t_count'])))\n",
    "bar_info._A = []\n",
    "cbar = fig.colorbar(bar_info)\n",
    "cbar.ax.tick_params(labelsize=100)\n",
    "cbar.ax.set_ylabel('\\n# of tweets\\n', rotation=90, fontsize = 100)\n",
    "ax.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b5d01",
   "metadata": {},
   "source": [
    "Answer 10.1: The map tells us about the distribution, and the associated color bar on the right helps decode the distribution. As stated in the title, the map is sub-divided by zip codes, and the data is from 2014, representing tweet counts from Indiana.\n",
    "\n",
    "In my opinion, the key takeaways are:\n",
    "- Areas that contribute most are geographically smaller (possibly indicating highly populated areas).\n",
    "- Although some areas contribute 50,000 or more tweets, most of the areas’ contribution is around 10k-15k.\n",
    "- More active users reside in the center than in the bordering areas.\n",
    "\n",
    "About data source: Data related to tweets is a subset of the data collected from Twitter that contains tweets from the United States of America for 2014. I use United States Census Bureau’s shapefiles to plot the geographical maps (available here: https://www2.census.gov/geo/tiger/TIGER2020/ZCTA5/)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc27fc5",
   "metadata": {},
   "source": [
    "### Assignment 11: Visualizing concepts and qualitative data\n",
    "\n",
    "All the questions and related answers of this assignment has been discussed below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a819a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read tweets\n",
    "# IL has more than 20 million tweets. Working with those will require\n",
    "# a lot of time. To minimize that, I am using first 20,000 of those tweets here.\n",
    "# you may want to go over this file: 'Assignments/Assignment5_6_8_9_10_11_12/ISLAM_SAMIUL.ipynb' on\n",
    "# my git hub repo to use a larger set.\n",
    "df_tweets_il = pd.read_csv('Assignment_Files/Data/tweets_il_20k.csv')\n",
    "\n",
    "# print out the head of the tweets to see how the look like\n",
    "print(df_tweets_il.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5f6dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean the data\n",
    "stop = set(stopwords.words('english'))\n",
    "exclude = set(string.punctuation)\n",
    "lemma = WordNetLemmatizer()\n",
    "\n",
    "def clean(text):\n",
    "    stop_free = ' '.join([word for word in str(text).lower().split() if word not in stop])\n",
    "    punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "    normalized = ' '.join([lemma.lemmatize(word) for word in punc_free.split()])\n",
    "    return normalized\n",
    "\n",
    "df_tweets_il['text_clean']=df_tweets_il['text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313b4b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print out the head of the data after cleaning\n",
    "df_tweets_il.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4045faaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate the cleaned tweeted text\n",
    "agg_tweets_il = df_tweets_il['text_clean'].str.cat(sep=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef7372",
   "metadata": {},
   "source": [
    "Question 11.1: Given that we have access to tweets, can you show a high-level representation of what people talk about the most?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22f9bae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate wordcloud\n",
    "wordcloud = WordCloud(width=1920, height=1080).generate(agg_tweets_il)\n",
    "plt.figure(figsize=(12, 9), dpi=1200).patch.set_facecolor('xkcd:white')\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "plt.title('Wordcloud of the tweets made from IL during 2014') # Instead of selecting 20 mil tweets,\n",
    "                                                        # I am using first 20,000 of those to reduce runtime.\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cfac848",
   "metadata": {},
   "source": [
    "Answer 11.1: This question can be answered in many different ways based on the level of details we want. However, to visualize a high-level understanding, word cloud can be one of the simplest when portraying precisely what we need to see. The figure attached shows that people talk more about ‘amp,’ ‘love,’ ‘time’ etc. and talk less about ‘eat,’ ‘music’, ‘wish’ etc. Even though this tells us the frequency of topics, we need sentiment analysis to understand their mindset (related to these topics; whether they are thinking positively or negatively)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd336fb",
   "metadata": {},
   "source": [
    "### Assignment 12: What does that even mean? Take #2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e53e72",
   "metadata": {},
   "source": [
    "Before discussing the improvements I made on the initial figure, I would like to talk about the initial figure briefly; what I was trying to visualize and how I was planning to do so. I had access to worldwide covid data for a period of two and a half months. We had two attributes: daily confirmed cases and daily deaths.\n",
    "\n",
    "My initial plan was to build an interactive visualization framework where the user will be able to see how the data is geographically distributed and a visual ratio of confirmed cases, deaths, and recovered. In the source data, we did not have information about how many people recovered each day. I took a portion of the difference between active cases and deaths to synthesize that variable. This process was not accurate, or this was in no way representative of actual data. However, I did this to design the framework only so that once I have the data, the framework would be able to render that too. In the initial design, I thought about a slider/date selector so that the user can change the date to see the situation of each day. If you follow the snapshot below (this is the same snapshot that I submitted for assignment 3 and 4), you should be able to relate how my visualization framework was doing. The four maps of the snapshot are four different stages; I put them together to show how the user was able to interact with them. I represented each country's data with a circle that had an optional feature of composing all the attributes or variables.¶\n",
    "\n",
    "The 'date selector' feature was not functional in my initial design. I used java and javascript to design that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc64d6bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Image(\"Assignment_Files/Assignment3/Assignment 3_Snapshot of Covid 19 Data Visualization Framework.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78d4d7d",
   "metadata": {},
   "source": [
    "I revamped the initial design and came up with a slightly different but significantly improved version of the framework to visualize that same data. I discarded the 'recovered' variable I synthesized in the new design and only focused on the 'daily confirmed cases' and 'daily deaths.' Now, I have two attributes/variables, and thus I decided to draw two different figures to visualize them. If I had access to the 'recovered' variable, I would have done another similar plot.\n",
    "\n",
    "In the new design, I decided not to use that circle to represent the attributes' values; instead, I used a gradient color scale to color code the countries on the entire map. I am listing the improvements of the new design below:\n",
    "\n",
    "- New design allows the user to zoom in/out on the map and drag it to reposition, which was not present in the initial design.\n",
    "- Although the initial design was compact since it was able to display the impacts of multiple variables in the same plot, it was cluttery. When the value increases, the circle's radius also increases, obstructing the user from seeing the underlying geo-areas.\n",
    "- I was not thinking about the color-blind community before (what would happen if someone could not distinguish between red, green, and yellow). In the new design, since I used gradient colors, they would at least be able to get the idea of relative comparison.\n",
    "- In the initial design, I handled countries that were doing really well (zero confirmed cases or deaths) and countries that do not share data equally by not drawing a circle for both of them. This approach could mislead the audience. Now, I have explicitly handled the countries we do not have any reporting for and added a check box to highlight them if needed.\n",
    "- It was so naive, but I did not include a title on the map describing what the users saw. I have added that here too.\n",
    "- 'Date selector' feature was not functional back then; I fixed it too. (It is not available on the html I am invoking below; these are available on the streamlit version that I prepared for presentation).\n",
    "- In the initial design, the geo-areas were not labeled. There was no way of knowing which area represented which country. I have used the open street map in the new design to resolve that.\n",
    "- The new design also has a feature to switch between dark and light mode, which should be helpful for people who work in both dark and light environments.\n",
    "- Now, user can hover over a country and get to see the name of the country along with daily confirmed cases and deaths.\n",
    "\n",
    "This new framework has been designed using python with the help of folium library. Later, to add more functionalities, I used streamlit to encapsulate all these. You may want to go over the codes below and the attached two maps (HTML pages) to have an idea of the of the new interactive framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62afb919",
   "metadata": {},
   "outputs": [],
   "source": [
    "world_map = gpd.read_file(\"Assignment_Files/Data/Shapefile_World/world-administrative-boundaries.shp\")\n",
    "world_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e4b710",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, as a covid 19 dataset, I am using a compact version. To understand how this version has been prepared from\n",
    "# the raw data, you may want to go over this file: 'Assignments/Assignment5_6_8_9_10_11_12/ISLAM_SAMIUL.ipynb' on\n",
    "# my git hub repo.\n",
    "with open('Assignment_Files/Data/datewise_data.pickle', 'rb') as handle:\n",
    "    datewise_data = pickle.load(handle)\n",
    "datewise_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff86956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map of confirmed cases for March 29, 2020\n",
    "d = '3/29/2020'\n",
    "merged_data = world_map.merge(datewise_data[d], on=\"name\")\n",
    "my_map = folium.Map(location=[42, 0], zoom_start=2.5)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data = merged_data,\n",
    "    name = 'COVID 19 Spread',\n",
    "    data = merged_data,\n",
    "    columns = ['name', 'countConfirmed'],\n",
    "    key_on = 'feature.properties.name',\n",
    "    fill_color = 'Oranges',\n",
    "    fill_opacity = 0.7,\n",
    "    line_opacity = 0.2,\n",
    "    legend_name = '# of Patients',\n",
    "    smooth_factor=0,\n",
    "    Highlight= True,\n",
    "    line_color = \"#000000\",\n",
    "    show=True,\n",
    "    overlay=True,\n",
    "    nan_fill_color = \"White\"\n",
    ").add_to(my_map)\n",
    "\n",
    "################\n",
    "# Here we add cross-hatching (crossing lines) to display the Null values.\n",
    "nans = merged_data[merged_data[\"countConfirmed\"].isnull()]['name'].values\n",
    "gdf_nans = merged_data[merged_data['name'].isin(nans)]\n",
    "sp = StripePattern(angle=45, color='black', space_color='black', line_color = \"black\", weight = 2, space_weight = 2, line_weight = 0, space_opacity = 0.75, line_opacity = 0.75)\n",
    "sp.add_to(my_map)\n",
    "folium.features.GeoJson(name=\"Unreported\",data=gdf_nans, style_function=lambda x :{'fillPattern': sp},show=True).add_to(my_map)\n",
    "\n",
    "\n",
    "#Hover\n",
    "# Add hover functionality.\n",
    "style_function = lambda x: {'fillColor': '#ffffff', \n",
    "                            'color':'#000000', \n",
    "                            'fillOpacity': 0.1, \n",
    "                            'weight': 0.1}\n",
    "highlight_function = lambda x: {'fillColor': '#000000', \n",
    "                                'color':'#000000', \n",
    "                                'fillOpacity': 0.50, \n",
    "                                'weight': 0.1}\n",
    "NIL = folium.features.GeoJson(\n",
    "    data = merged_data,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=['name','countConfirmed', 'countDeaths'],\n",
    "        aliases=['Country','Confirmed Cases', 'Deaths'],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n",
    "    )\n",
    ")\n",
    "my_map.add_child(NIL)\n",
    "my_map.keep_in_front(NIL)\n",
    "#sample_map2\n",
    "\n",
    "loc = 'Distribution of COVID-19 Daily Confirmed Cases '+'('+d+')'\n",
    "title_html = '''\n",
    "             <h3 align=\"center\" style=\"font-size:32px\"><b>{}</b></h3>\n",
    "             '''.format(loc)\n",
    "my_map.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "\n",
    "\n",
    "# Add dark and light mode. \n",
    "folium.TileLayer('cartodbdark_matter',name=\"dark mode\",control=True).add_to(my_map)\n",
    "folium.TileLayer('cartodbpositron',name=\"light mode\",control=True).add_to(my_map)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We add a layer controller. \n",
    "folium.LayerControl(collapsed=False).add_to(my_map)\n",
    "################\n",
    "\n",
    "\n",
    "#my_map.save('confirmed.html')\n",
    "my_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b892f8f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map of daily deaths for March 29, 2020\n",
    "d = '3/29/2020'\n",
    "merged_data = world_map.merge(datewise_data[d], on=\"name\")\n",
    "my_map = folium.Map(location=[42, 0], zoom_start=2.5)\n",
    "\n",
    "folium.Choropleth(\n",
    "    geo_data = merged_data,\n",
    "    name = 'COVID 19 Spread',\n",
    "    data = merged_data,\n",
    "    columns = ['name', 'countDeaths'],\n",
    "    key_on = 'feature.properties.name',\n",
    "    fill_color = 'Oranges',\n",
    "    fill_opacity = 0.7,\n",
    "    line_opacity = 0.2,\n",
    "    legend_name = '# of Patients',\n",
    "    smooth_factor=0,\n",
    "    Highlight= True,\n",
    "    line_color = \"#000000\",\n",
    "    show=True,\n",
    "    overlay=True,\n",
    "    nan_fill_color = \"White\"\n",
    ").add_to(my_map)\n",
    "\n",
    "################\n",
    "# Here we add cross-hatching (crossing lines) to display the Null values.\n",
    "nans = merged_data[merged_data[\"countConfirmed\"].isnull()]['name'].values\n",
    "gdf_nans = merged_data[merged_data['name'].isin(nans)]\n",
    "sp = StripePattern(angle=45, color='black', space_color='black', line_color = \"black\", weight = 2, space_weight = 2, line_weight = 0, space_opacity = 0.75, line_opacity = 0.75)\n",
    "sp.add_to(my_map)\n",
    "folium.features.GeoJson(name=\"Unreported\",data=gdf_nans, style_function=lambda x :{'fillPattern': sp},show=True).add_to(my_map)\n",
    "\n",
    "\n",
    "#Hover\n",
    "# Add hover functionality.\n",
    "style_function = lambda x: {'fillColor': '#ffffff', \n",
    "                            'color':'#000000', \n",
    "                            'fillOpacity': 0.1, \n",
    "                            'weight': 0.1}\n",
    "highlight_function = lambda x: {'fillColor': '#000000', \n",
    "                                'color':'#000000', \n",
    "                                'fillOpacity': 0.50, \n",
    "                                'weight': 0.1}\n",
    "NIL = folium.features.GeoJson(\n",
    "    data = merged_data,\n",
    "    style_function=style_function, \n",
    "    control=False,\n",
    "    highlight_function=highlight_function, \n",
    "    tooltip=folium.features.GeoJsonTooltip(\n",
    "        fields=['name','countConfirmed', 'countDeaths'],\n",
    "        aliases=['Country','Confirmed Cases', 'Deaths'],\n",
    "        style=(\"background-color: white; color: #333333; font-family: arial; font-size: 12px; padding: 10px;\") \n",
    "    )\n",
    ")\n",
    "my_map.add_child(NIL)\n",
    "my_map.keep_in_front(NIL)\n",
    "#sample_map2\n",
    "\n",
    "loc = 'Distribution of COVID-19 Daily Deaths '+'('+d+')'\n",
    "title_html = '''\n",
    "             <h3 align=\"center\" style=\"font-size:32px\"><b>{}</b></h3>\n",
    "             '''.format(loc)\n",
    "my_map.get_root().html.add_child(folium.Element(title_html))\n",
    "\n",
    "\n",
    "\n",
    "# Add dark and light mode. \n",
    "folium.TileLayer('cartodbdark_matter',name=\"dark mode\",control=True).add_to(my_map)\n",
    "folium.TileLayer('cartodbpositron',name=\"light mode\",control=True).add_to(my_map)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# We add a layer controller. \n",
    "folium.LayerControl(collapsed=False).add_to(my_map)\n",
    "################\n",
    "\n",
    "\n",
    "#my_map.save('deaths.html')\n",
    "my_map"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fe73031",
   "metadata": {},
   "source": [
    "I have prepared a more complete version of these two maps with better features. The implementation of that can be found in the 'FinalProject' folder of my repository. Batch file named 'EXECUTEME.BAT' should be able to deploy it locally on a Windows machine. I have also deployed it using streamlit cloud. You may want to see it here: https://share.streamlit.io/samiul-gmu/csi703_spring2022_samiul/main/Final_Project_Web_App_Deployable.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e682975",
   "metadata": {},
   "source": [
    "### Web App: The cell below contains the code for the web app; it has been built following the instructions for final notebook submission. I cannot run from here since this is a notebook file, and I used streamlit to design the app. Instead, I included the same code in a separate .py file that can be deployable. On top, I have also included a batch file to keep the execution process simple (simply run the 'ExecuteWebApp.bat')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60954ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "from wordcloud import WordCloud\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "st.set_page_config(layout = 'wide')\n",
    "\n",
    "st.markdown(\"\"\"\n",
    "    <style>\n",
    "    .big-font {\n",
    "        font-size:80px !important;\n",
    "        text-align:center;\n",
    "    }\n",
    "    </style>\n",
    "\"\"\", unsafe_allow_html=True)\n",
    "st.markdown('<p class=\"big-font\">Final Notebook</p>', unsafe_allow_html=True)\n",
    "\n",
    "option = st.selectbox(\n",
    "     'Select the map you want to see:',\n",
    "     #('Daily Confirmed Cases', 'Daily Deaths', 'Aggregated Confirmed Cases', 'Aggregated Deaths'))\n",
    "     ('Correlation, comparisons, and trends', 'Distributions and part-to-whole', 'Geospatial', 'Concepts and qualitative'))\n",
    "\n",
    "if (option == 'Correlation, comparisons, and trends'):\n",
    "    # Take input from the excel file and load it to a dataframe\n",
    "    df = pd.read_excel('Assignment_Files/Data/forestfires.xlsx')\n",
    "    \n",
    "    # Convert the month column from string to int\n",
    "    df[\"month\"].replace({\"jan\": 1, \"feb\": 2, \"mar\": 3, \"apr\": 4, \"may\": 5, \"jun\": 6, \"jul\": 7, \"aug\": 8, \"sep\": 9, \"oct\": 10, \"nov\": 11, \"dec\": 12}, inplace=True)\n",
    "    df[\"month\"] = df[\"month\"].astype(int)\n",
    "    \n",
    "    \n",
    "    var = st.multiselect(\n",
    "     \"Select variable(s):\",\n",
    "     ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain', 'area'],\n",
    "     ['FFMC', 'DMC', 'DC', 'ISI', 'temp', 'RH', 'wind', 'rain', 'area'])\n",
    "    \n",
    "    if(len(var)==0):\n",
    "        st.write('Select variable(s) to proceed!')\n",
    "    else:\n",
    "        preVar = ['X', 'Y', 'month', 'day']\n",
    "        df = df[preVar+var]\n",
    "\n",
    "        # Plot a pair plot color-coded by months to see if they show any relation\n",
    "        fig = px.parallel_coordinates(df, color=\"month\",\n",
    "                                     color_continuous_scale=px.colors.diverging.Tealrose,\n",
    "                                     color_continuous_midpoint=6, width=1500, height=800,\n",
    "                                      title=\"Relations between weather/dryness variables while grouping them by month\")\n",
    "        st.plotly_chart(fig)\n",
    "        \n",
    "elif (option == 'Distributions and part-to-whole'):\n",
    "    df = pd.read_excel('Assignment_Files/Data/forestfires.xlsx')\n",
    "    df_sum = df.groupby(['month']).sum()\n",
    "    \n",
    "    bar = st.checkbox('Bar Plot', value=True)\n",
    "    pie = st.checkbox('Pie Plot', value=True)\n",
    "     \n",
    "\n",
    "    c1, c2 = st.columns(2)\n",
    "    if(bar):\n",
    "        with c1:\n",
    "            # Plot the aggregated area for each month to identify how devasting each month was?\n",
    "            # Set the size of the plot for a high-resolution plot and setup the fonts for ticks, legend, and title.\n",
    "            df_area = df_sum[['area']]\n",
    "            months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "            df_bar_plot = df_area.loc[months]\n",
    "            x = df_bar_plot.index.tolist()\n",
    "            y = df_bar_plot['area'].tolist()\n",
    "            x_pos = np.arange(len(x))\n",
    "            print(x_pos)\n",
    "            plt.figure(figsize=(20, 20), dpi=500)\n",
    "            \n",
    "            plt.bar(x_pos, y, color=['lightcoral','lightskyblue','yellow','yellowgreen','grey','pink','blue','darkgreen','cyan','magenta','violet','gold'])\n",
    "            plt.xticks(x_pos, x)\n",
    "            plt.xticks(fontsize=18)\n",
    "            plt.yticks(fontsize=18)\n",
    "            #plt.legend(fontsize=18)\n",
    "            plt.xlabel('\\nMonth',fontsize=18)\n",
    "            plt.ylabel('Burnt Area (HA)\\n',fontsize=18)\n",
    "            plt.title('Burnt Forest Area by Month\\n',fontsize=35)\n",
    "            plt.legend('',frameon=False)\n",
    "            st.pyplot(plt)\n",
    "    if(bar and pie):\n",
    "        with c2:\n",
    "            df_pie_plot = df_sum[['wind', 'area']]\n",
    "            months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "            df_pie_plot = df_pie_plot.loc[months]\n",
    "            x = df_pie_plot.index.tolist()\n",
    "            y = df_pie_plot['area'].tolist()\n",
    "            percent = [100*ey / sum(y) for ey in y]\n",
    "            colors = ['lightcoral','lightskyblue','yellow','yellowgreen','grey','pink','blue','darkgreen','cyan','magenta','violet','gold']\n",
    "            fig, ax = plt.subplots(figsize=(20,20))\n",
    "            patches, texts = ax.pie(y, colors = colors, counterclock=False, startangle=-270, radius=1)\n",
    "            labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(x, percent)]\n",
    "            plt.title('Part-to-whole Distribution of\\nForest Fire', loc='center',fontsize=35)\n",
    "            \n",
    "            plt.legend(patches, labels, title = 'Month', loc='center', bbox_to_anchor=(0,1),\n",
    "                       fontsize=20, title_fontsize=25)\n",
    "            st.pyplot(fig)\n",
    "    if(not bar and pie):\n",
    "        with c1:\n",
    "            df_pie_plot = df_sum[['wind', 'area']]\n",
    "            months = ['jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec']\n",
    "            df_pie_plot = df_pie_plot.loc[months]\n",
    "            x = df_pie_plot.index.tolist()\n",
    "            y = df_pie_plot['area'].tolist()\n",
    "            percent = [100*ey / sum(y) for ey in y]\n",
    "            colors = ['lightcoral','lightskyblue','yellow','yellowgreen','grey','pink','blue','darkgreen','cyan','magenta','violet','gold']\n",
    "            fig, ax = plt.subplots(figsize=(20,20))\n",
    "            patches, texts = ax.pie(y, colors = colors, counterclock=False, startangle=-270, radius=1)\n",
    "            labels = ['{0} - {1:1.2f} %'.format(i,j) for i,j in zip(x, percent)]\n",
    "            plt.title('Part-to-whole Distribution of\\nForest Fire', loc='center',fontsize=35)\n",
    "            \n",
    "            plt.legend(patches, labels, title = 'Month', loc='center', bbox_to_anchor=(0,1),\n",
    "                       fontsize=20, title_fontsize=25)\n",
    "            st.pyplot(fig)\n",
    "elif (option == 'Geospatial'):\n",
    "    # import relevant data\n",
    "    data=pd.read_csv(\"Assignment_Files/Data/zipcode_wise_tweet_count_IN.csv\")\n",
    "    # load the selected subset of the US map (shapefile) containin IN only.\n",
    "    # I am using a backup of the partial shapefile.\n",
    "    # If you want to learn more on how I selected the subset and did a backup, you may\n",
    "    # want to go over this file: 'Assignments/Assignment5_6_8_9_10_11_12/ISLAM_SAMIUL.ipynb' on\n",
    "    # my git hub repo.\n",
    "    with open('Assignment_Files/Data/us_map.pickle', 'rb') as handle:\n",
    "        us_map = pickle.load(handle)\n",
    "    # merge them based on ZCTA5CE10 which is zip-code\n",
    "    map_data = us_map.merge(data, on=\"ZCTA5CE10\")\n",
    "    map_data['log2_t_count'] = np.log2(map_data['t_count'])\n",
    "    \n",
    "    c1, c2, c3 = st.columns(3)\n",
    "    with c2:\n",
    "        log = st.radio(\n",
    "            \"Do you want to consider logrithmic value of number of tweets?\",\n",
    "            ('No', 'Yes'))\n",
    "        \n",
    "        var = 't_count'\n",
    "        \n",
    "        if(log=='No'):\n",
    "            var = 't_count'\n",
    "        else:\n",
    "            var = 'log2_t_count'\n",
    "        \n",
    "        fig, ax = plt.subplots(1, figsize=(10, 10))\n",
    "        fig.patch.set_facecolor('white')\n",
    "        plt.xticks(rotation=90)\n",
    "        plt.yticks(fontsize=50)\n",
    "        map_data.plot(column=var, cmap=\"Reds\", linewidth=1, ax=ax, edgecolor=\"0\")\n",
    "        plt.title('\\n\\nDistribution of Tweets Made from Indiana during 2014\\nMap is Sub-divided into Zip Codes', fontdict = {'fontsize' : 17.5})\n",
    "        bar_info = plt.cm.ScalarMappable(cmap=\"Reds\", norm=plt.Normalize(vmin=0, vmax= max(map_data[var])))\n",
    "        bar_info._A = []\n",
    "        cbar = fig.colorbar(bar_info)\n",
    "        cbar.ax.tick_params(labelsize=12.5)\n",
    "        cbar.ax.set_ylabel('\\n# of tweets\\n', rotation=90, fontsize = 12.5)\n",
    "        ax.axis(\"off\")\n",
    "        st.pyplot(fig)\n",
    "    \n",
    "elif (option == 'Concepts and qualitative'):\n",
    "    # read tweets\n",
    "    # IL has more than 20 million tweets. Working with those will require\n",
    "    # a lot of time. To minimize that, I am using first 20,000 of those tweets here.\n",
    "    # you may want to go over this file: 'Assignments/Assignment5_6_8_9_10_11_12/ISLAM_SAMIUL.ipynb' on\n",
    "    # my git hub repo to use a larger set.\n",
    "    df_tweets_il = pd.read_csv('Assignment_Files/Data/tweets_il_20k.csv')\n",
    "    \n",
    "    c1, c2, c3 = st.columns(3)\n",
    "    with c2:\n",
    "        nTweets = st.slider('Select number of tweets to use:', 100, 20000, 1000)\n",
    "    df_tweets_il = df_tweets_il[0:nTweets]\n",
    "    # clean the data\n",
    "    stop = set(stopwords.words('english'))\n",
    "    exclude = set(string.punctuation)\n",
    "    lemma = WordNetLemmatizer()\n",
    "    \n",
    "    def clean(text):\n",
    "        stop_free = ' '.join([word for word in str(text).lower().split() if word not in stop])\n",
    "        punc_free = ''.join(ch for ch in stop_free if ch not in exclude)\n",
    "        normalized = ' '.join([lemma.lemmatize(word) for word in punc_free.split()])\n",
    "        return normalized\n",
    "    \n",
    "    df_tweets_il['text_clean']=df_tweets_il['text'].apply(clean)\n",
    "    \n",
    "    # aggregate the cleaned tweeted text\n",
    "    agg_tweets_il = df_tweets_il['text_clean'].str.cat(sep=' ')    \n",
    "    \n",
    "    \n",
    "    with c2:    \n",
    "        # generate wordcloud\n",
    "        wordcloud = WordCloud(width=1920, height=1080).generate(agg_tweets_il)\n",
    "        plt.figure(figsize=(12, 9), dpi=1200).patch.set_facecolor('xkcd:white')\n",
    "        plt.imshow(wordcloud, interpolation='bilinear')\n",
    "        plt.axis(\"off\")\n",
    "        plt.title('Wordcloud of the tweets made from IL during 2014', fontsize = 20) # Instead of selecting 20 mil tweets,\n",
    "                                                                # I am using first 20,000 of those to reduce runtime.\n",
    "        st.pyplot(plt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
